{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Elements of Statistical Learning\n",
    "## Data Mining, Inference, and Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 Introduction\n",
    "\n",
    "## Basic Concept\n",
    "\n",
    "### Some tasks\n",
    "\n",
    "- Predict whether a patient, hospitalized due to a heart attack, will have a second heart attack. The prediction is to be based on demographic, diet and clinical measurements for that patient.\n",
    "- Predict the price of a stock in 6 months from now, on the basis of company performance measures and economic data.\n",
    "- Identify the numbers in a handwritten ZIP code, from a digitized image.\n",
    "- Estimate the amount of glucose in the blood of a diabetic person, from the infrared absorption spectrum of that person's blood.\n",
    "- Identify the risk factors for prostate cancer, based on clinical and demographic variables.\n",
    "\n",
    "### Learning from data\n",
    "\n",
    "| Methods | Features | Output measurement | Training set | Learner |\n",
    "|---------|----------|--------------------|--------------|---------|\n",
    "|Supervised learning|Yes|Yes|Yes|Yes|\n",
    "|Unsupervised learning|Yes|No|Yes|Yes|\n",
    "\n",
    "#### Notice\n",
    "\n",
    "- Output measurement: Quantitative/qualitative(categorical)\n",
    "- Training set: A set of observed objects.\n",
    "- Learner: A prediction model which can predict outputs for unseen objects.\n",
    "- Supervised learning: Outcome variable guide the learning process.\n",
    "\n",
    "## Example 1: Email Spam\n",
    "\n",
    "Predict whether the email was spam. (A classification problem) \n",
    "\n",
    "- Features: Word frequency\n",
    "\n",
    "|Words|george|you|your|hp|free|hpl|!|our|re|edu|remove|\n",
    "|-|------|---|----|--|----|---|-|---|--|---|------|\n",
    "|spam|0.00|2.26|1.38|0.02|0.52|0.01|0.51|0.51|0.13|0.01|0.28|\n",
    "|email|1.27|1.27|0.44|0.90|0.07|0.43|0.11|0.18|0.42|0.29|0.01|\n",
    "    \n",
    "- Training set: Lots of emails with labels of output measurement\n",
    "- Output measurement: Categorical label, `email` or `spam`\n",
    "- Learner: A rule like this\n",
    "```c\n",
    "if (percent_george < 0.6) && (percent_you > 1.5) return mail_is_spam;\n",
    "else return mail_is_email;\n",
    "```\n",
    "or like this\n",
    "```c\n",
    "if (0.2 * percent_you − 0.3 * percent_george) > 0 return mail_is_spam;\n",
    "else return mail_is_email;\n",
    "```\n",
    "\n",
    "### Misclassify\n",
    "\n",
    "- False positive: let spam get through\n",
    "- False negative: filter out good email\n",
    "\n",
    "## Example 2: Prostate Cancer\n",
    "\n",
    "Predict the log of PSA (lpsa) from a number of measurements.\n",
    "PSA: Prostate Specific Antigen (前列腺特异性抗原)\n",
    "\n",
    "- Features: Clinic measures\n",
    "- Training set:\n",
    "    ![img1-1.png](images/img1-1.png)\n",
    "- Output measurement: Quantitative data (lpsa)\n",
    "- Learner: Regression learner\n",
    "\n",
    "## Example 3: Handwritten Digit Recognition\n",
    "\n",
    "Predict the identify (0, 1, ..., 9) of images from the 16 × 16 matrix of pixel\n",
    "intensities.\n",
    "- Features: ???\n",
    "- Training set:\n",
    "    ![img1-2.png](images/img1-2.png)\n",
    "- Output measurement: A identified number.\n",
    "- Learner: Classification learner. (Or frequently, a newrual network)\n",
    "\n",
    "## Supervised/unsupervised\n",
    "\n",
    "- **Supervised learning**: Outcome variable guide the learning process.\n",
    "- **Unsupervised learning**: Observe only the feature and have no measurement of the outcome.\n",
    "\n",
    "## Example 4: DNA Expression Microarrays \n",
    "(A sample of unsupervised learning)\n",
    "\n",
    "A gene expression dataset collects together the expression values from a series of DNA microarray experiments, with each column representing an experiment.\n",
    "\n",
    "### Data\n",
    "![img1-3.png](images/img1-3.png)\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Which samples are most similar to each other, in terms of their expression profiles across genes?\n",
    "2. Which genes are most similar to each other, in terms of their expression profiles across samples?\n",
    "3. Do certain genes show very high (or low) expression for certain cancer samples?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 Overview of Supervised Learning\n",
    "\n",
    "## Concepts about supervised learning\n",
    "\n",
    "|Word| Meaning|\n",
    "|-|-|\n",
    "|**inputs**|predictors / independent variables / features|\n",
    "|**outputs**|responses / dependent variables / quantitative or qualitative|\n",
    "|**quantitative outputs**|some measurements are bigger than others|\n",
    "|**qualitative outputs**|some measurements belong to some class, categorial, discrete variables|\n",
    "|**Regression**|predict quantitative outputs|\n",
    "|**Classification**|predict qualitative outputs|\n",
    "\n",
    "Both regression and classification are a task in function approximation.\n",
    "**ordered categorical**: There is an ordering between the values (small, medium and large)\n",
    "**Qualitative variables**: Targets, often represented by a single binary digit or bit as 0 or 1, or else by −1 and 1 (dummy variables). K-level qualitative variable is represented by a vector of K binary variables or bits, only one of which is \"on\" at a time. $[0 1 0 \\dots 0]^T$\n",
    "\n",
    "### Symbols\n",
    "$$\n",
    "X = [X_1 X_2 \\dots X_p] = \\left[\n",
    "\\begin{array}{cccc}\n",
    "X_{11} & X_{12} & \\dots  & X_{1p} \\\\\n",
    "X_{21} & X_{22} & \\dots  & X_{2p} \\\\\n",
    "\\dots  & \\dots  & \\ddots & \\dots  \\\\\n",
    "X_{N1} & X_{N2} & \\dots  & X_{Np} \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "- $X$: input variable\n",
    "- $X_i$: $i$-th input conponent\n",
    "- $Y$: quantitative outputs\n",
    "- $G$: qualitative outputs\n",
    "- $x_i$: observed value (scalar or vector)\n",
    "- $\\hat Y$: prediction of $Y$, given $X$\n",
    "- $(x_i, y_i)$ or $(x_i, g_i)$: training data\n",
    "- $i = 1, \\dots, N$\n",
    "\n",
    "For a two-class $G$, one approach is to denote the binary coded target\n",
    "as $Y$ , and then treat it as a quantitative output. The predictions $\\hat Y$ will\n",
    "typically lie in $[0, 1]$, and we can assign to $\\hat G$ the class label according to\n",
    "whether $\\hat y$ > 0.5.\n",
    "\n",
    "## Linear Models and Least Squares\n",
    "### 1. Linear models\n",
    "Given a vector of inputs $X^T = (X_1, X_2, \\dots, X_p)$, we have model:\n",
    "$$\\hat Y = \\hat{\\beta_0} + \\sum_{j=1}^p X_j\\hat{\\beta_j}$$\n",
    "where $\\hat{\\beta_0}$ is called intercept, or *bias*.\n",
    "\n",
    "- Often we include constant variable 1 in X:\n",
    "$$\n",
    "X = [1, X_1, X_2, \\dots X_p] = \\left[\n",
    "\\begin{array}{ccccc}\n",
    "1 & X_{11} & X_{12} & \\dots,  & X_{1p} \\\\\n",
    "1 & X_{21} & X_{22} & \\dots  & X_{2p} \\\\\n",
    "\\dots & \\dots  & \\dots  & \\ddots & \\dots  \\\\\n",
    "1 & X_{N1} & X_{N2} & \\dots  & X_{Np} \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "We have: $\\hat Y = X^T\\hat\\beta$\n",
    "($\\hat Y_i$ can not only be a scalar)\n",
    "\n",
    "### 2. Least Squares:\n",
    "1. Pick the coefficients of $\\beta$ to minimize the residual sum of squares (RSS)\n",
    "    \n",
    "    $RSS(\\beta)=\\sum_{i=1}^N(y_i-x_i^T\\beta)^2$ (Quadratic function and always have minimun, but mey not be unique)\n",
    "2. Write in matrix notation:\n",
    "    \n",
    "    $RSS(\\beta)=(y-X\\beta)^T(y-X\\beta)$, where $X \\in \\mathbb{R}^{N\\times p}$ and $y \\in \\mathbb{R}^N$\n",
    "3. Differentiating RSS on $\\beta$, we have normal equation:\n",
    "    \n",
    "    $X^T(y-X\\beta)=0$\n",
    "4. $\\beta = (X^TX)^{-1}X^Ty$\n",
    "\n",
    "#### Matrix trace of $A$: $tr(A)$\n",
    "1. $tr A = \\sum_i A_{ii}$\n",
    "2. $tr k = k$\n",
    "3. $tr AB = tr BA$, $tr ABC = tr BCA = tr CAB$\n",
    "3. $tr A = tr A^T$\n",
    "4. $\\frac{\\partial{tr AB}}{\\partial{A}} = B^T$\n",
    "5. $\\frac{\\partial{f(A)}}{\\partial{A^T}} = (\\frac{\\partial{f(A)}}{\\partial{A}})^T$\n",
    "6. $\\frac{\\partial{tr ABA^TC}}{\\partial{A}} = CAB+C^TAB^T$\n",
    "7. $\\frac{\\partial{tr ABA^TC}}{\\partial{A^T}} = B^TA^TC^T+BA^TC$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
